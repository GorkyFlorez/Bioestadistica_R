---
title: "Bioestadistica con R"
author: "Ing. Gorky Florez Castillo"
output:
  html_document:
    code_folding: show
    df_print: paged # para hacer que las tablas sean como excel kable
    keep_md: true
    toc: true
    toc_float: true
    toc_depth: 2
    css: styles.css
    theme: flatly
    number_sections: true
    
date: "`r format(Sys.time(), '%B %d, %Y')`"


---



<div style="display: flex; justify-content: flex-start;">
  <a href="https://twitter.com/gorky_flor14144" target="_blank">
    <img src="https://cdn.cms-twdigitalassets.com/content/dam/legal-twitter/sharing-card.png.twimg.768.png" alt="Twitter" style="width: 50px; margin-right: 10px;">
  </a>
  <a href="https://www.linkedin.com/in/gorky-florez-castillo-865663250/" target="_blank">
    <img src="https://store-images.s-microsoft.com/image/apps.31120.9007199266245564.44dc7699-748d-4c34-ba5e-d04eb48f7960.bc4172bd-63f0-455a-9acd-5457f44e4473?h=210" alt="LinkedIn" style="width: 30px; margin-right: 10px;">
  </a>
  <a href="https://github.com/GorkyFlorez" target="_blank">
    <img src="https://foundations.projectpythia.org/_images/GitHub-logo.png" alt="GitHub" style="width: 50px; margin-right: 10px;">
  </a>
  <a href="https://web.facebook.com/yordy.florez.1/?_rdc=1&_rdr" target="_blank">
    <img src="https://upload.wikimedia.org/wikipedia/commons/b/b9/2023_Facebook_icon.svg" alt="Facebook" style="width: 40px;">
  </a>
  <a href="https://www.instagram.com/gorkiflorez/" target="_blank">
    <img src="https://img.freepik.com/vector-gratis/icono-redes-sociales-vector-instagram-7-junio-2021-bangkok-tailandia_53876-136728.jpg?w=1380&t=st=1711218465~exp=1711219065~hmac=46b49a382cbd43853079f7e9c9c6e73153fd5fa6baca6154abce5b47fb9efa69" alt="Facebook" style="width: 40px;">
  </a>
  <a href="https://www.researchgate.net/profile/Gorky-Florez-Castillo" target="_blank">
    <img src="https://pbs.twimg.com/profile_images/1676195477795078145/EFykJcDr_400x400.png" alt="Facebook" style="width: 40px;">
  </a>
  <a href="https://scholar.google.es/citations?user=NB1rMykAAAAJ&hl=es" target="_blank">
    <img src="https://events.cms.ok.ubc.ca/wp-content/uploads/sites/121/2023/03/google-scholar-300x300.png" alt="Facebook" style="width: 40px;">
  </a>
  <a href="https://id.pinterest.com/gorkyflorezcastillo/" target="_blank">
    <img src="https://i.pinimg.com/280x280_RS/f6/e9/3a/f6e93a06b500b2d87ffd32e1f56f7c6f.jpg" alt="Facebook" style="width: 40px;">
  </a>
</div>


<link rel="icon" type="image/png" href="favicon.ico"/>
 


<style>
/*----------LOGO above TOC---------*/
#TOC::before {
  content: "";
  display: block;
  height: 200px; /* Ajusta la altura según sea necesario */
  margin: 2em 20px 40px 20px; /* Ajusta los márgenes según sea necesario */
  background-image: url("https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTEd3h2-4bBTbWytGRCE0-7YyxNIamg6Nq88Ndas-oWCyq3Xt7NfFDPg79gNQ&s"); /* Cambia la URL de la imagen según corresponda */
  background-size: contain;
  background-position: center center;
  background-repeat: no-repeat;
}
</style>




<div style="display: flex; justify-content: center;">

<img src="https://avatars.githubusercontent.com/u/513560?s=200&v=4" style="width: 100px; margin-right: 20px;">
<img src="https://www.r-project.org/Rlogo.png" style="width: 100px;">

</div>


# **_Cargar los datos en R_** 

## Datos de cargados manualmente
En R, cargar datos manualmente se refiere al proceso de introducir los datos directamente en el código del programa, en lugar de cargarlos desde un archivo externo. Esto se logra asignando los valores directamente a un objeto en R.

Por ejemplo, en el fragmento de código proporcionado, se crea un vector llamado "datos" que contiene una serie de valores numéricos. Cada valor separado por comas dentro de los paréntesis corresponde a un dato individual en el vector.
```{r }
datos <- c(41.59, 46.55, 73.38, 51.06, 51.94, 75.73, 56.91, 31.02, 39.70, 
           43.32, 68.36, 55.40, 56.01, 51.66, 41.66, 76.80, 57.47, 20.50, 
           60.52, 42.91, 33.98, 46.73, 34.61, 39.07, 40.62, 24.70, 62.57, 
           52.30, 32.93, 68.81, 56.40, 45.57, 63.43, 63.17, 62.32, 60.33, 
           58.31, 49.07, 45.41, 44.29, 39.58, 46.88, 31.02, 82.53, 68.12, 
           33.15, 43.96, 43.00, 61.70, 48.75)
```

## Cargar datos mediante URL
Cargar datos mediante URL en R implica acceder a conjuntos de datos alojados en servidores remotos a través de enlaces URL. Para esto, se utiliza la función read.table() o una función similar, pasando la URL como argumento al parámetro file. Es importante asegurarse de que la URL proporcione acceso directo al archivo de datos, y de que los datos estén en un formato compatible con la función de lectura que se está utilizando.

En el ejemplo proporcionado, se muestra cómo cargar datos desde una URL específica que apunta a un archivo de datos en formato tabular. La función read.table() se utiliza para leer el archivo y almacenar los datos en un objeto en R.
```{r }
url = 'https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo'
datos <- read.table(file=url, header=T)
datos
```

<div style="display: flex; justify-content: center;">

<img src="https://foundations.projectpythia.org/_images/GitHub-logo.png" style="width: 200px;">

</div>


En este caso, la URL apunta al archivo "medidas_cuerpo" alojado en GitHub. La opción header = TRUE se utiliza para indicar que la primera fila del archivo contiene los nombres de las columnas.

## Cargar datos en formato txt

Cuando se trata de cargar datos en formato de archivo de texto (por ejemplo, .txt), R proporciona varias funciones, entre ellas read.table(), que permite leer datos tabulares desde un archivo de texto. La función read.table() es versátil y puede manejar una variedad de formatos de archivo de texto, incluidos aquellos con delimitadores específicos, como tabulaciones o comas.

Aquí tienes un ejemplo de cómo cargar datos desde un archivo de texto en formato .txt:
```{r }
panes  = read.table("data1.txt", header = T) #heade: los encabezados son los titulos
panes
tortas = read.table("data2.txt", header = T)
tortas
vara =  read.table("varespec.txt", header = T)
vara
```

<div style="display: flex; justify-content: center;">

<img src="https://images.wondershare.com/recoverit/article/what_is_txt_file.png" style="width: 200px;">
</div>


En este ejemplo:

"data1.txt" es el nombre del archivo de texto que contiene los datos que deseas cargar. Asegúrate de que el archivo esté en el mismo directorio de trabajo que tu script de R, o especifica la ruta completa al archivo si está en un directorio diferente.

header = TRUE indica que la primera fila del archivo contiene los nombres de las columnas. Si los datos no tienen encabezados, puedes establecer header = FALSE o simplemente omitir este parámetro.

La función read.table() interpreta automáticamente el contenido del archivo de texto y lo carga en un objeto de datos en R. Una vez ejecutado el código, el objeto panes contendrá los datos del archivo "data1.txt", y estarán listos para ser utilizados en análisis posteriores dentro de R.



## Cargar datos en CSV
Para cargar datos en formato CSV (Comma-Separated Values) en R, puedes utilizar la función read.csv() o read_csv() del paquete readr. Ambas funciones son capaces de leer datos de archivos CSV y cargarlos en un objeto de datos en R. Aquí te muestro cómo hacerlo con read.csv():

```{r }
#install.packages(readr)  comando para instalar paquetes en R
library(readr)
varas1 = read.csv("varespec.csv")
varas1
```
En este ejemplo:

"varespec.csv" es el nombre del archivo CSV que contiene los datos que deseas cargar. Asegúrate de que el archivo esté en el mismo directorio de trabajo que tu script de R, o especifica la ruta completa al archivo si está en un directorio diferente.

La función read.csv() interpreta automáticamente el contenido del archivo CSV y lo carga en un objeto de datos en R. Los datos se almacenan en el objeto varas1 y están listos para ser utilizados en análisis posteriores dentro de R.

## Cargar datos en Excel

Para cargar datos desde un archivo de Excel en R, puedes usar la función read_excel() del paquete readxl. Aquí tienes un ejemplo de cómo hacerlo:
```{r }
library(readxl)
Mandarinas = read_excel("RMODUL1.xlsx", sheet = 1) # sheet es el numero o nombre de la hoja en Excel
Mandarinas 
str(Mandarinas) # cual es la estructura de los datos
dim(Mandarinas) # cuales son las dimenciones de los datos 
summary(Mandarinas) # estadistica basica de los datos
```
En este ejemplo:

"RMODUL1.xlsx" es el nombre del archivo de Excel del que deseas cargar los datos. Asegúrate de que el archivo esté en el mismo directorio de trabajo que tu script de R, o especifica la ruta completa al archivo si está en un directorio diferente.

sheet = 1 especifica que quieres cargar los datos de la primera hoja del archivo de Excel. Puedes cambiar el número o el nombre de la hoja según sea necesario.

Después de cargar los datos, puedes utilizar print(), str(), dim() y summary() para explorar los datos cargados y obtener información sobre su estructura, dimensiones y estadísticas básicas.




# **_Graficos basicos de estadistica_** 

## Creamos un data frame con las columnas region, sexo, hg y peso

```{r }
## Creamos un data frame con las columnas region, sexo, hg y peso

# Creamos un nuevo data frame llamado dagraf utilizando la función data.frame().
# Este data frame tendrá cuatro columnas: region, sexo, Hg y peso.
# La función sample() genera muestras aleatorias de un vector dado.
# La función factor() convierte un vector en un factor, que es una variable categórica.
# La función rep() repite los elementos de un vector.
# La función runif() genera números aleatorios uniformemente distribuidos.
# La función rnorm() genera números aleatorios de una distribución normal.

dagraf = 
  data.frame(region = sample(
    factor(
      rep(c("Pacifico Norte", "Pacifico Central", "Pacifico Sur"), times = 1000), 
      levels = c("Pacifico Norte", "Pacifico Central", "Pacifico Sur")), 
    81),
    sexo = sample(
      factor(
        rep(c("macho", "hembra"), times = 1000), 
        levels = c("macho", "hembra")), 
      81), 
    Hg = rep(runif(n = 27, min = 15, max = 28), times = 3),
    peso = rnorm(n = 81, mean = 75, sd = 4.5))

# Llamamos a la variable dagraf para ver los datos que hemos creado.
dagraf      

# Utilizamos la función str() para ver la estructura de los datos en el data frame dagraf.
str(dagraf) 
```
En resumen, este código crea un data frame llamado dagraf con cuatro columnas: region, sexo, Hg y peso. Las columnas region y sexo contienen datos categóricos aleatorios, la columna Hg contiene datos numéricos generados aleatoriamente y la columna peso contiene datos numéricos generados aleatoriamente de una distribución normal. Después de crear el data frame, se imprime su estructura utilizando la función str().


## Elaboracion de histograma 
hist(dagraf$Hg): Crea un histograma de la columna 'Hg' (mercurio) del data frame 'dagraf'. La función hist() genera un histograma de las frecuencias de los datos.

hist(dagraf[, 3]): Crea un histograma de la tercera columna del data frame 'dagraf', que corresponde a la columna 'Hg' (mercurio) también. La notación [, 3] selecciona todas las filas y la tercera columna del data frame 'dagraf'.

par(mfrow =c(1,2)): Esta línea configura el diseño de los gráficos en 1 fila y 2 columnas, lo que significa que los gráficos subsiguientes se mostrarán uno al lado del otro en la misma fila.

hist(dagraf$Hg): Crea otro histograma de la columna 'Hg' (mercurio) del data frame 'dagraf'. Como estamos dentro de un entorno gráfico dividido (par(mfrow =c(1,2))), este histograma se mostrará al lado del primero.

hist(dagraf[, 3]): Crea otro histograma de la tercera columna del data frame 'dagraf', que también es la columna 'Hg' (mercurio). Este histograma se mostrará al lado del primero debido a la configuración de par(mfrow =c(1,2)).

```{r }
#MEJORANDO EDICIONES
#Por ejemplo, podemos cambiar el nombre a los ejes (axes) y agregar un título.

# Configuramos el diseño de la disposición de los gráficos en 3 filas y 3 columnas
par(mfrow = c(3, 3))

# Creamos un histograma de la concentración de mercurio (Hg)
hist(dagraf$Hg,
     xlab = "Concentracion de Hg (mg/100 ml)", # Etiqueta del eje x
     ylab = "Frecuencia",                       # Etiqueta del eje y
     main = "Histograma de la concentracion de Hg") # Título del gráfico

# Creamos un histograma del peso corporal
hist(dagraf$peso,
     xlab = "Peso corporal (kg)",               # Etiqueta del eje x
     ylab = "Frecuencia",                       # Etiqueta del eje y
     main = "Histograma del peso corporal")     # Título del gráfico

# Creamos un histograma de la concentración de mercurio (Hg) sin mostrar la frecuencia relativa
hist(dagraf$Hg,
     xlab = "Concentracion de Hg (mg/100 ml)", # Etiqueta del eje x
     ylab = "Frecuencia (%)",                   # Etiqueta del eje y
     main = "",                                  # No se muestra título del gráfico
     freq = FALSE)                               # No mostrar frecuencia relativa

# Creamos un histograma del peso de peces con ajustes adicionales
hist(dagraf$peso,
     xlab = "Peso (kg)",                        # Etiqueta del eje x
     ylab = "Frecuencia",                       # Etiqueta del eje y
     main = "Histograma del peso de peces",     # Título del gráfico
     freq = TRUE,                                # Mostrar frecuencia absoluta
     cex.axis = 0.8,                             # Tamaño de las etiquetas de los ejes x e y
     cex.lab = 1.2)                              # Tamaño de las etiquetas de los ejes x e y

# Creamos un histograma del peso de peces con color personalizado
hist(dagraf$peso,
     xlab = "Peso (kg)",                        # Etiqueta del eje x
     ylab = "Frecuencia",                       # Etiqueta del eje y
     main = "Histograma del peso de peces",     # Título del gráfico
     freq = TRUE,                                # Mostrar frecuencia absoluta
     cex.axis = 1.2,                             # Tamaño de las etiquetas de los ejes x e y
     cex.lab = 1.2,                              # Tamaño de las etiquetas de los ejes x e y
     col = "#43B2FC85")                          # Color personalizado

# Creamos un histograma del peso de peces con color predefinido
hist(dagraf$peso,
     xlab = "Peso (kg)",                        # Etiqueta del eje x
     ylab = "Frecuencia",                       # Etiqueta del eje y
     main = "Histograma del peso de peces",     # Título del gráfico
     freq = TRUE,                                # Mostrar frecuencia absoluta
     cex.axis = 1.2,                             # Tamaño de las etiquetas de los ejes x e y
     cex.lab = 1.2,                              # Tamaño de las etiquetas de los ejes x e y
     col = "lightblue")                          # Color predefinido

# Creamos un histograma del peso de peces con color de fondo y borde personalizados
hist(dagraf$peso,
     xlab = "Peso (kg)",                        # Etiqueta del eje x
     ylab = "Frecuencia",                       # Etiqueta del eje y
     main = "Histograma del peso de peces",     # Título del gráfico
     freq = TRUE,                                # Mostrar frecuencia absoluta
     cex.axis = 1.2,                             # Tamaño de las etiquetas de los ejes x e y
     cex.lab = 1.2,                              # Tamaño de las etiquetas de los ejes x e y
     col = "#90EE90",                            # Color de fondo personalizado
     border = "red")                             # Color del borde personalizado

# Creamos un histograma del peso de peces con densidad y ángulo de inclinación personalizados
hist(dagraf$peso,
     xlab = "Peso (kg)",                        # Etiqueta del eje x
     ylab = "Frecuencia",                       # Etiqueta del eje y
     main = "Histograma del peso de peces",     # Título del gráfico
     freq = TRUE,                                # Mostrar frecuencia absoluta
     cex.axis = 1.2,                             # Tamaño de las etiquetas de
     col = "blue", border = "red", density = 5, angle = 90)

par(mfrow =c(1,1))


```


### Histograma con ggplot2
Creación del Data Frame: Se crea un nuevo data frame llamado 'PlantGrowth2' con dos columnas: 'group', que contiene el valor 'A' repetido la misma cantidad de veces que los datos de peso, y 'datos', que contiene los datos de peso.

Cálculo de Estadísticos Descriptivos y Pendiente: Utilizando la librería 'dplyr', se calculan estadísticos descriptivos como los cuantiles 25% y 75%, y se estima la pendiente de la curva de normalidad basada en estos cuantiles.

Realización del Gráfico con ggplot2: Se utiliza ggplot2 para generar un gráfico avanzado que incluye un histograma de densidad, una curva de densidad, una curva de normalidad teórica y una línea vertical punteada en la media. También se realiza una prueba de Shapiro-Wilk para evaluar la normalidad de los datos.

Personalización del Gráfico: Se personalizan los aspectos visuales del gráfico, como el color de llenado y borde, las etiquetas de ejes y título, el estilo del gráfico, la posición del título y la línea vertical punteada en la media. Además, se agrega una anotación para mostrar el valor p de la prueba de Shapiro-Wilk.

```{r }
## Adicionando curva de normalidad

# Creamos un nuevo data frame 'PlantGrowth2' con una sola columna 'datos' que contiene los datos de peso
# y otra columna 'group' que tiene el valor 'A' repetido la misma cantidad de veces que los datos de peso
PlantGrowth2 <- data.frame(group = rep("A", length(dagraf$peso)),
                           datos = dagraf$peso)

# Cargamos la librería 'dplyr' necesaria para usar la función '%>%'
library(dplyr)

# Calculamos los estadísticos descriptivos y la pendiente de la curva de normalidad
intptemedia <- PlantGrowth2 %>%
  group_by(group) %>%
  summarize(q25 = quantile(dagraf$peso, 0.25),
            q75 = quantile(dagraf$peso, 0.75),
            norm25 = qnorm(0.25),
            norm75 = qnorm(0.75),
            pendiente = (q25 - q75) / (norm25 - norm75),
            int = q25 - pendiente * norm25,
            media = mean(dagraf$peso)) %>%
  select(group, pendiente, int, media)

# Realizamos el gráfico avanzado con ggplot2, que incluye histograma, curva de densidad y curva de normalidad
# Se añade una línea vertical punteada en la media
library(ggplot2)
shapiro.test(dagraf$peso)  # Prueba de Shapiro-Wilk para evaluar la normalidad de los datos
ggplot(data = dagraf, aes(x = peso)) +
  geom_histogram(aes(y = ..density..), fill = "cyan3", color = "black") +# Histograma de densidad
  geom_density(fill = "skyblue", color = "blue", alpha = 0.4) + # Curva de densidad
  stat_function(fun = dnorm, colour = "firebrick",    # Curva de normalidad teórica
                args = list(mean = mean(dagraf$peso), sd = sd(dagraf$peso))) +
  theme_minimal() +  # Estilo del gráfico
  labs(title = "Histograma con curva normal teórica", x = "Valores", y = "Densidad") +# Etiquetas de ejes y título
  theme(plot.title = element_text(hjust = 0.5)) +  # Ajuste de posición del título
  geom_vline(data = intptemedia, aes(xintercept = media, colour = group),# Línea vertical en la media
             linetype = "dashed", size = 1.5) +  # Estilo de la línea
  theme(legend.position = "none") +      # No mostrar leyenda
  annotate("text", x=83,y =0.14,label ="P-value = 0.765",color ="black",size=3)  # Anotación de p-value
```

### Grafico de qqplot 

```{r }
##### Groficos de qq plot de la prueba de normalidad de los datos

# Establecemos un diseño de una fila y dos columnas para mostrar dos gráficos QQ-Plot
par(mfcol = c(1, 2))

# Graficamos el QQ-Plot para los datos de mercurio (Hg)
qqnorm(dagraf$Hg, pch = 19, col = "gray50", main = "QQ-Plot Concentración de mercurio")
qqline(dagraf$Hg, col = "red")  # Agregamos una línea de referencia roja

# Graficamos el QQ-Plot para los datos de peso
qqnorm(dagraf$peso, pch = 19, col = "red", main = "QQ-Plot Concentración de Pesos")
qqline(dagraf$peso, col = "blue")  # Agregamos una línea de referencia azul

# Restauramos el diseño de una sola celda
par(mfcol = c(1, 1))
```
Interpretación:

Los gráficos QQ-Plot se utilizan para visualizar si un conjunto de datos sigue una distribución normal.
En el primer gráfico (QQ-Plot de concentración de mercurio), los puntos están cerca de la línea de referencia roja, lo que sugiere que los datos de concentración de mercurio pueden seguir aproximadamente una distribución normal.
En el segundo gráfico (QQ-Plot de concentración de pesos), los puntos también están relativamente cerca de la línea de referencia azul, lo que indica que los datos de peso también pueden seguir una distribución normal, aunque hay algunas desviaciones en los extremos.


## Elaboracion de grafico de cajas y bigotes

Gráfico de Boxplot 1 (dagraf$peso):

Este gráfico muestra la distribución de los datos de peso en el conjunto de datos.
La caja representa el rango intercuartílico (IQR), que abarca desde el primer cuartil (Q1) hasta el tercer cuartil (Q3).
La línea dentro de la caja representa la mediana (Q2), que es el valor que divide el conjunto de datos en dos partes iguales.
Los "bigotes" muestran la dispersión de los datos más allá de los cuartiles, excluyendo los valores atípicos.
La etiqueta del eje y indica "Frecuencia", que es la frecuencia de ocurrencia de los diferentes valores de peso en el conjunto de datos.
Gráfico de Boxplot 2 (dagraf$peso, col = "forestgreen"):

Es similar al primer gráfico, pero con una diferencia de color. En este caso, la caja y los puntos del gráfico se representan en un tono verde oscuro ("forestgreen").
Gráfico de Boxplot 3 (dagraf$Hg, col = "lightblue", main = "Diagrama de cajas concent. Mercurio"):

Este gráfico muestra la distribución de los datos de concentración de mercurio en el conjunto de datos.
Se establece la etiqueta del eje y como "frecuencias", lo que sugiere que la frecuencia de ocurrencia de los diferentes valores de concentración de mercurio se está representando.
La caja y los puntos del gráfico se muestran en un tono azul claro ("lightblue").
Además, se proporciona un título al gráfico, que es "Diagrama de cajas concent. Mercurio".

```{r }
par(mfcol = c(1, 3))
## gr?ficos de boxplots o cajas
boxplot(dagraf$peso, ylab = "Frecuencia")
boxplot(dagraf$peso, ylab = "Frecuencia", col = "forestgreen")
boxplot(dagraf$Hg, ylab = "frecuencias", col= "lightblue", main= "Diagrama 
        de cajas concent. Mercurio")
par(mfcol = c(1, 1))
```

## Manipular elementos de caja y vigotes
Definición de colores:

Se definen dos vectores de colores (col.g1 y col.g2) que se utilizarán en los gráficos de caja para representar diferentes regiones.
Boxplot por Región:

Se crea un gráfico de caja donde el eje x representa las regiones y el eje y representa el peso en kg.
Se utilizan los colores definidos en col.g2 para cada región.
El parámetro vertical = TRUE indica que los gráficos de caja se mostrarán en posición vertical.
Se establecen tamaños de letra para los ejes (cex.axis) y etiquetas (cex.lab).
Se proporciona un título al gráfico.
Boxplot por Región (sintaxis alternativa):

Se muestra otro gráfico de caja utilizando una sintaxis alternativa donde se especifica el nombre de la variable (peso) y el nombre del conjunto de datos (dagraf) directamente.
Boxplot por Sexo:

Se genera un gráfico de caja separando los datos de peso por género (macho y hembra).
Boxplot por Región y Sexo:

Se crea un gráfico de caja donde se compara el peso según la región y el género.
Boxplot por Región y Sexo (horizontal):

Similar al gráfico anterior, pero se muestra en posición horizontal (horizontal = TRUE), con ejes de menor tamaño (cex.axis = 0.6) y etiquetas de ejes giradas (las = 2).
Personalización adicional de Boxplot por Región:

Otro gráfico de caja por región, con colores diferentes (yellow, blue, forestgreen) y etiquetas de región personalizadas (names = c("PN", "Central", "Sur")).
Estos gráficos de caja permiten comparar la distribución del peso en diferentes regiones y géneros, lo que puede ayudar a identificar patrones o diferencias significativas en los datos. Además, la personalización de colores y otros parámetros permite ajustar el aspecto de los gráficos para satisfacer las necesidades específicas de visualización.
```{r }
# Manipular elementos del grofico
levels(dagraf$region)
col.g1 = c("green", "blue", "grey80") # definir colores
col.g2 = c("GREEN", "blue", "grey80") # definir colores

boxplot(dagraf$peso ~ dagraf$region, 
        xlab = "Regiones", ylab="Frecuencia (Peso Kg)", col = col.g2, vertical = T,
        cex.axis = 1.2, cex.lab = 1.4, 
        main = "Diagrama de cajas del peso por regiones") #el vertical puedo cambiar a horizontal
boxplot(peso ~ region, data = dagraf)
boxplot(peso ~ sexo, data = dagraf)
boxplot(peso ~ region + sexo, data = dagraf)
boxplot(peso ~ region + sexo, data = dagraf,
        horizontal = TRUE, cex.axis = 0.6, las = 2)
boxplot(peso ~ region, data = dagraf, 
        xlab = "Frecuencia", 
        col = c("yellow", "blue", "forestgreen"), 
        vertical = T,
        cex.axis = 1.2, cex.lab = 1.4,
        names = c("PN", "Central", "Sur"))

# Establecer margenes

```

Elaboracion de boxplot de forma nativa de boxplot

```{r }
# Establecer margenes
par(mfcol = c(1, 1))
par(mar = c(6, 5, 1.5, 0))

boxplot(peso ~ region, data = dagraf, 
        col = "gray95",
        xlab = "", ylab = "",
        type = "n",xaxt = "n", yaxt = "n", 
        frame.plot = F, main = "Ejemplo 1")

axis(1, at = seq(1, 3, by = 1), 
     labels = c("Pacifico Norte", "Pacifico Central", "Pacifico Sur"), 
     cex.axis = 1.2)

axis(2, las = 1)

mtext("Region", side = 1, line = 3, cex = 1.5)
mtext("Frecuencia", side = 2, line = 2.6, cex = 1.5)

box(bty="l",lwd=1.1)

```






# **_test estadisticos basicos_** 

## test de Normalidad Shapiro-Wilk
```{r}
# instalamos un paquete que trae sobre pruebas de normalidad
library("nortest")
#Desarrollando el test de Normalidad

#### Test de Shapiro-Wilk

#Este test se emplea para contrastar normalidad cuando el 
#tamaño de la muestra es menor de 50. Para muestras grandes 
#es equivalente al test de kolmogorov-Smirnov.

library("dplyr")
library("ggpubr")

#Datos de medidas de dientes
#H0 : las medidas de los dientes siguen una tendencia de normalidad.
#HA : las medidas de los dientes no siguen una tendencia de normalidad.

#Ejemplo 1

quirus=ToothGrowth  # Asignamos los datos

str(quirus)         # Estructura de los datos
summary(quirus)     # Estadistica basica
sd(quirus$dose)     # Desviacion estandar de dosis
sd(quirus$len)      # desviacion estandar de la longitud de los dientes
var(quirus$dose) 
var(quirus$len)
```


Los datos del conjunto "quirus" corresponden a un estudio sobre el crecimiento dental en sujetos expuestos a diferentes dosis de una sustancia ("supp") y midiendo la longitud de los dientes ("len"). La estructura del conjunto de datos es la siguiente:

len: Variable numérica que representa la longitud de los dientes.
supp: Factor con 2 niveles ("OJ" y "VC") que indica el tipo de suplemento utilizado.
dose: Variable numérica que indica la dosis de la sustancia administrada.
El resumen estadístico de "quirus" muestra que:

La longitud de los dientes ("len") tiene una media de aproximadamente 18.81 unidades, con una mínima de 4.20 y una máxima de 33.90. La desviación estándar es de aproximadamente 7.65 y la varianza es de alrededor de 58.51.
La dosis ("dose") tiene una media de aproximadamente 1.167 unidades, con una mínima de 0.5 y una máxima de 2. La desviación estándar es de aproximadamente 0.63 y la varianza es de alrededor de 0.40.
Estos estadísticos describen la distribución y variabilidad de las medidas de longitud de los dientes y las dosis administradas en el estudio. Las medidas de longitud tienen una mayor variabilidad en comparación con las dosis administradas, como lo sugieren las desviaciones estándar y las varianzas más altas.


```{r}
library(ggpubr)
#grafico de densidad
A= ggdensity(quirus$len, main = "grafico de densidad de longitud de quirus", 
          xlab="longitud de quirus")

#gr?fico qqplot
B = ggqqplot(quirus$len, main= "grafico QQ quirus", 
         xlab="dispersion de longitud quirus")

C= ggarrange(A,B,
               labels = c("A", "B"),
               nrow = 1,ncol = 2)
C
```

```{r}
par(mfcol = c(1, 2))
#histograma
hist(quirus$len)
#boxplot
boxplot(quirus$len)
par(mfcol = c(1, 1))
```

## test de Normalidad de Kolmogorov-Smirnov

El resultado del test de normalidad de Lilliefors (que es una variante del test de Kolmogorov-Smirnov) se interpreta de la siguiente manera:

Para el conjunto de datos "quirus$len" (longitud de los dientes), el valor p obtenido es 0.172. Este valor p es mayor que el nivel de significancia comúnmente utilizado (0.05), lo que indica que no hay suficiente evidencia para rechazar la hipótesis nula de normalidad. Por lo tanto, podemos asumir que los datos de longitud de los dientes siguen una distribución normal.


```{r}
#aplicando el test shapiro para conocer la tendencia de los datos
lillie.test(quirus$len) #test de normalidad de Kolmogorov-Smirnov

```
Para el conjunto de datos "dagraf$peso" (peso), el valor p obtenido es 0.9169. Al ser mucho mayor que 0.05, no hay suficiente evidencia para rechazar la hipótesis nula de normalidad. Por lo tanto, los datos de peso también parecen seguir una distribución normal.
```{r}
lillie.test(dagraf$peso) #test de normalidad de Kolmogorov-Smirnov

```
Sin embargo, para el conjunto de datos "dagraf$Hg" (concentración de mercurio), el valor p obtenido es extremadamente pequeño (5.442e-10), muy por debajo del nivel de significancia de 0.05. Esto sugiere que hay suficiente evidencia para rechazar la hipótesis nula de normalidad. Por lo tanto, los datos de concentración de mercurio no siguen una distribución normal.
```{r}
lillie.test(dagraf$Hg)
```

### Grafico de QQ - Plot
```{r}
A= ggqqplot(dagraf$Hg, main= "grafico QQ Mercurio", 
         xlab="dispersion de concent Mercurio")

B= ggqqplot(dagraf$peso, main= "grafico QQ Peso", 
         xlab="dispersion de concent Peso")

C= ggqqplot(quirus$len, main= "grafico QQ longitud ", 
         xlab="dispersion de concent longitud de los dientes")

library(ggplot2)
library(caTools)
library(benchmarkme)
library(memuse)
library(robustbase)
library(qqplotr)

# ploting data with proper labels 
# And adding line with proper properties

D =ggplot(mapping = aes(sample = quirus$len)) + 
  stat_qq_point(size = 2,color = "red") + 
  stat_qq_line(color="green") + 
  xlab("x-axis") + ylab("y-axis")

E= ggarrange(A,B,C,D,
             labels = c("A", "B", "C", "D"),
             nrow = 2,ncol = 2)
E
```

### test de Normalidad de Kolmogorov-Smirnov y modificacion de Lillefors

Se realiza una prueba de Kolmogorov-Smirnov (KS) para determinar si los datos de longitud de los dientes (quirus$len) provienen de una distribución normal. El KS test permite estudiar si una muestra procede de una población con una determinada distribución, no limitándose únicamente a la distribución normal.

En el código proporcionado, se utiliza la función ks.test() para llevar a cabo esta prueba. Los argumentos son:

x: Los datos que se están evaluando (quirus.len).pnorm: La distribución teórica de referencia que se está probando, en este caso, la distribución normal. mean(quirus.len): La media de los datos de longitud de los dientes.
sd(quirus$len): La desviación estándar de los datos de longitud de los dientes.
La salida del código proporcionará el resultado del KS test, indicando si hay suficiente evidencia para rechazar la hipótesis nula de que los datos provienen de una distribución normal o no.

```{r}
#El test de Kolmogorov-Smirnov permite estudiar si una muestra
#procede de una poblacion con una determinada distribucion 
#(media y desviacion topica), no esta limitado unicamente 
#a la distribuci?n normal. Se ejecuta con la funcion ks.test().

mtcars

ks.test(x = quirus$len,"pnorm", mean(quirus$len), sd(quirus$len))

```



# **_T Student, una muestra_**

## test de Normalidad Shapiro-Wilk
El estadistico aplicado es el t-student. 
```{r}

#Recomendado para trabajar con muestras peque?as. 
#Sin embargo, cuando se trabaja con muestras grandes 
#los datos son pr?ximos a una distribuci?n aproximadamente normal.

#Ejemplo 1
#Se realiza un experimento donde se midio la produccion de 
#vainas de frijol por cada mata producida, en 12 unidades 
#experimentales sometidas bajo las mismas condiciones.

frijol = c(18,11,17,10,20,25,13,16,25,20,19,20)
```
Hipotesis

 H0= Los datos provienen de una distribuci?n normal.
 H1: Los datos presentan una distribuci?n asim?trica.

Probamos el supuesto de normalidad de nuestros datos
```{r}
shapiro.test(frijol) #shapiro me dice que hay tendencia a la normalidad
```
Aceptamos H0: Nuestros datos cumplen con el supuesto de normalidad.

Estime el intervalo de confianza al 95% para el rendimiento 
promedio del numero de vainas producidas por cada mata de frijol. 
Los datos presentan una distribucion normal.

Soluci?n:

El intervalo de confianza es construido a trav?s de la prueba t.test (x)

```{r}
t.test(frijol)

#El intervalo de confianza al 95% obtenido es: [14.78 a 20.88], 
#lo que representa es el intervalo de la media de la poblaci?n de 
#las vainas de frijol. As? mismo se obtienen otros resultados 
#como la media de la muestra de: 17.83.

#Se nos brinda informaci?n adicional del valor calculado de t=12.86, 
#los grados de libertad (df=11), obtenidos de la 
#formula gl=n-1 (numero de observaciones menos uno), y 
#la probabilidad resultante (p-value = 5.673e-08), en nuestro caso 
#es menor a 0.05, por lo que nuestro resultado es significativo
#dado la hip?tesis por defecto.

#H0: media igual a 0
#H1: media es diferente de 0
```

```{r}
#para ver gr?ficamente
boxplot(frijol,col="yellow", main="Diagrama de cajas Frijol")
points(mean(frijol), pch=20, cex = 1.5)
text(17.5, "Promedio", col="red", font=8 )
median(frijol)
```

```{r}
#Por tanto concluimos que existe diferencia significativa en cuanto a la 
#producci?n de vainas en cada planta dentro de esa muestra de 12 plantas.

#Nivel de ingreso de padres de familia en la prov. Tambopata

social=c(900,850,700,980,500,450,1025,1800,1000,640)
shapiro.test(social)

#H0: los salarios de los 1o padres no son significativamente diferentes
#H1: los salarios de los 1o padres si son significativamente diferentes

t.test(social)

#conclusiOn

#El valor de la  p-value = 4.444e-05, nos indica que significativamente hay
#una diferencia en los salarios de los 10 pdf.

```

## T Test para 2 muestras independientes


```{r}
#El dataset births del paquete openintro contiene informaci?n sobre
#150 nacimientos junto con informaci?n de las madres. 
#Se quiere determinar si existen evidencias significativas de que el
#peso de los reci?n nacidos cuyas madres fuman (f) difiere de aquellos
#cuyas madres no fuman (nf).

#install.packages("openintro") #necesitamos de estos paquetes para trabajar 
#la base de satos births
library(openintro)
#install.packages("tidyverse")
library(tidyverse)

data(births)
head(births, 4)
print(births)
str(births)
```

```{r}
# 1. Hip?tesis

#H0: no hay diferencia entre las medias poblacionales: ??(nf)?????(f)=0
#Ha: si hay diferencia entre las medias poblacionales: ??(nf)?????(f)???0


#2. Par?metro estimado (estad?stico)
#Diferencia entre las medias muestrales:

smoker = births %>% filter(smoke == "smoker") %>% pull(weight)
nonsmoker = births %>% filter(smoke == "nonsmoker") %>% pull(weight)

mean(nonsmoker) - mean(smoker)

#3. Condiciones para aplicar un t-test
#Independencia: Se trata de un muestreo aleatorio donde el 
#tama?o de las muestras no supera el 10% de todos los nacimientos 
#Se puede afirmar que los eventos son independientes.
```

```{r}
#Normalidad:
#muestra el histograma ggplo2
ggplot(births,aes(x = weight)) + 
  geom_histogram(aes(y = ..density.., colour = smoke)) +
  facet_grid(.~ smoke) +
  theme_bw() + theme(legend.position = "none")
```

```{r}
# Para observar en los otros gr?ficos
par(mar = c(2, 2, 2, 2))
par(mfrow = c(1, 2))
qqnorm(nonsmoker, xlab = "", ylab = "",
       main = "nonsmoker", col = "firebrick")
qqline(nonsmoker)
qqnorm(smoker, xlab = "", ylab = "",
       main = "smoker", col = "springgreen4")
qqline(smoker)
par(mfrow = c(1, 1))
```

```{r}
#Aplico el test de normalidad
shapiro.test(smoker)
shapiro.test(nonsmoker) 

#Los gr?ficos qqnorm muestran asimetr?a hacia la izquierda y los test
#encuentran evidencias significativas de que los datos no 
#proceden de poblaciones con distribuci?n normal. Sin embargo, 
#dado que el tama?o de cada grupo es mayor que 30 se puede considerar 
#que el t-test sigue siendo suficientemente robusto, aunque es necesario 
#mencionarlo en las conclusiones. 
# Un test no param?trico basado en la 
#mediana (Mann-Withney-Wilcoxon test) o un test de Bootstraping ser?an m?s 
#adecuados. Otra opci?n ser?a estudiar si los datos an?malos son excepciones
#que se pueden excluir del an?lisis.
```



```{r}
#Datos de crecimiento de plantulas con perturbio y no perturbio, consideramos
#muestras pareadas porque sobre el mismo tratamiento estoy desarrollando


plantulas = read_excel("plantulas.xls", sheet=1)

#H0=el nro de plantulas entre parcelas, del testigo y del evento sean similares
#HA=el nro de plantulas entre parcelas, del testigo y del evento son diferentes

str(plantulas)  # Estructura de los datos
head(plantulas) 
boxplot(plantulas$Testigo, plantulas$Perterbado) # boxplot de dos columnas de los datos
shapiro.test(plantulas$Testigo)  # el p valor es mayor a 0.05 por lo cual si cumple con la normaldiad 
shapiro.test(plantulas$Perterbado) # Si cumple la normaldiad 
t.test(plantulas$Testigo, plantulas$Perterbado, paired = T) 
#Aplico el de muestras pareadas

#Conclusiones
# existe diferencia significativa entre el nro de pl?ntulas evaluadas entre 
# las parcelas testigo y las perturbadas.

```

## Prueba no parametrica de Man Wihtney o Wilcoxon
Nos reconoce a traves del test de wilcoxon. Esta prueba es para comparar dos muestras que no tienen tendencia a una distribucion de normalidad

```{r}
#instalamos paquete Boot
library("boot")
library("car")
library("dplyr")
library("ggpubr")

#trabajamos con el archivo fumasa
fumones = read.table("fumasa.txt", header=T)
names(fumones)
fumones

fumones=data.frame(fumones)
```

```{r}
par(mfrow = c(1, 2))
boxplot(fumones$edad ~ fumones$genero, col = "green",
        main = "Diferencias por grupo")

#para los que fuman y no fuman
boxplot(fumones$edad ~ fumones$fuman, col = "green",
        main = "Diferencias por grupo")
par(mfrow = c(1, 1))

library(ggstatsplot)

data = data.frame(edad= c(fumones$edad),
                  genero =(fumones$genero))

ggbetweenstats(data, genero, edad,
               
               type = "p",
               conf.level = 0.95)
```

```{r}
#Selecciono para aplicar el test de normalidad
sifuman = fumones %>% filter(fuman == "si") %>% pull(edad)
nofuman = fumones %>% filter(fuman == "no") %>% pull(edad)

mean(sifuman) - mean(nofuman)
```

```{r}
#Aplico el test de normalidad para validar la no normalidad
shapiro.test(sifuman)
shapiro.test(nofuman)  #validamos la no tendencia a la normalidad
```

Existe diferencias significativas por que el p valor es menor a 0.05
```{r}
#Aplico el test de Mann Wihtne (wilcox.tes)
wilcox.test(edad~fuman, fumones) 
```


# **_ANOVA_**

```{r}
medley = read.table("medley.txt", header = T)
medley
str(medley)

#reorganizamos los niveles del factor categ?rico en un orden m?s l?gico.

medley$zinc = factor(medley$zinc, levels = c("HIGH", "MED",
                                             "LOW", "BACK"), ordered = F)

str(medley$zinc)

#Evaluamos la normalidad/homogeneidad de la varianza utilizando 
#el diagrama de cajas de la diversidad de especies vs de zinc

boxplot(diversidad~zinc, medley)
```
Concluimos que no hay alteraciones obvias de Normalidad u homogeneidad de la varianza, el diagramas de caja no son asimetricos y no varian mucho en tamaño


```{r}
#Evaluamos la suposici?n de homogeneidad de varianza con una 
#tabla y / o gr?fica de media vs varianza

plot(tapply(medley$diversidad, medley$zinc, mean),
     tapply(medley$diversidad, medley$zinc, var))
#no existe una relaci?n buena entre las medias y varianzas.
```

Ahora realizamos la prueba H0, que las medias de los grupos poblacionales son iguales: ejecutamos un an?lisis de varianza (ajuste del modelo lineal) de la diversidad de especies en comparaci?n con el grupo a nivel de zinc y examinamos los diagn?sticos (grafico residual) ojo dividir la pantalla en 2 fil y 2 col
```{r}
help(aov) #vemos de que trata el argumento aov
par(mfrow=c(2, 2))
medley.aov = aov(diversidad ~ zinc, medley)
plot(medley.aov)
par(mfrow=c(1, 1))
```

No hay alteraciones obvias de la normalidad o la homogeneidad de la varianza (no obvias forma de cu?a en residuos, grafico Q-Q normal aproximadamente lineal). Tener en cuenta que los valores de D de Cook sin sentido en ANOVA.


```{r}
#no hay alteraciones obvias de la normalidad o la homogeneidad de la 
#varianza (no obvias forma de cu?a en residuos, gr?fico Q-Q normal
#aproximadamente lineal). Tener en cuenta que los valores de D de
#Cook sin sentido en ANOVA.

#Ahora construimos la tabla de ANOVA

anova(medley.aov)
#Por tanto concluimos manifestando que se rechaz H0, que las medias de los
#grupos de poblaci?n son iguales, se encontr? que ZINC tiene un
#impacto significativo en la DIVERSIDAD de las diatomeas 
#(F3,30 = 3.939, P = 0.018).

#Ahora haremos el an?lisis post hot mediante el proc. "TUYKEYS", para
#ver las difrencias entre cada una.

library(multcomp)#habilitamos esta libreria para que nos de simultanea
library(sandwich)
library(TH.data)
#mente todas las comparaciones
summary(glht(medley.aov, linfct = mcp(zinc = "Tukey")))

#Concluimos que la diversidad de especies de diatomeas es 
#significativamente mayor en sitios con bajo contenido de zinc que
#con alto contenido de zinc sitios (t15 = 3.333, P = 0.011). 
#Ning?n otro H0 es rechazado. Nota, los valores P ajustados de Tukey son
#basado en procedimientos robustos que no estaban disponibles para Quinn
#y Keough (2002). Cuanto mas
#la prueba reciente de Tukey utiliza procedimientos de aleatorizaci?n
#y, por lo tanto, los valores P exactos difieren de una carrera a otra.

boxplot(diversidad~zinc, medley)
library(ggstatsplot)
library(rstantools)
ggbetweenstats(
  data = medley,
  x = zinc,
  y = diversidad
)

```



```{r}
library(readxl)
mademuerta = read_excel("densidad.xls", sheet=1)
str(mademuerta)
head(mademuerta)
mademuerta=data.frame(mademuerta)
#identificamos el n?mero de grupos y cantidad de observaciones por grupo 
#para determinar si es un modelo equilibrado. Tambi?n se calculan la
#media y desviaci?n t?pica de cada grupo

table(mademuerta$Estad_descompos)
aggregate(Densidad ~ Estad_descompos, data = mademuerta, FUN = mean)
aggregate(Densidad ~ Estad_descompos, data = mademuerta, FUN = sd)

#La representaci?n gr?fica mas ?til antes de realizar un ANOVA es el modelo 
#Box-Plot.

ggplot(data = mademuerta, aes(x = Estad_descompos, y = Densidad, 
                              color = Estad_descompos)) + geom_boxplot() + theme_bw()

ggbetweenstats(
  data = mademuerta,
  x = Estad_descompos,
  y = Densidad
)

#2.Verificar condiciones para un ANOVA
par(mfrow = c(1,1))
par(mfrow = c(2,2))
qqnorm(mademuerta[mademuerta$Estad_descompos == "A1_5","Densidad"],main = "A1_5")
qqline(mademuerta[mademuerta$Estad_descompos == "A1_5","Densidad"])
qqnorm(mademuerta[mademuerta$Estad_descompos == "B2","Densidad"],main = "B2")
qqline(mademuerta[mademuerta$Estad_descompos == "B2","Densidad"])
qqnorm(mademuerta[mademuerta$Estad_descompos == "C2_5","Densidad"],main = "C2_5")
qqline(mademuerta[mademuerta$Estad_descompos == "C2_5","Densidad"])
qqnorm(mademuerta[mademuerta$Estad_descompos == "D3","Densidad"],main = "D3")
qqline(mademuerta[mademuerta$Estad_descompos == "D3","Densidad"])

#Volvemos a la pantalla simpe
par(mfrow = c(1,1))

#Dado que los grupos tienen mas de 50 eventos se emplea el test de 
#Kolmogorov-Smirnov con la correcci?n de Lilliefors. La funci?n en 
#R se llama lillie.test() y se encuentra en el paquete nortest. Si fuesen 
#menos de 50 eventos por grupo se emplear?a el test Shapiro-Wilk.

require(nortest)
by(data = mademuerta,INDICES = mademuerta$Estad_descompos,
   FUN = function(x){ lillie.test(x$Densidad)}) #sale tendencia normal todos

by(data = mademuerta,INDICES = mademuerta$Estad_descompos,
   FUN = function(x){ shapiro.test(x$Densidad)}) #sale tendencia normal todos

#Para evaluar la varianza entre grupos (homocedasticidad)

fligner.test(Densidad ~ Estad_descompos,mademuerta)


require(car)
leveneTest(Densidad ~ Estad_descompos,mademuerta,center = "median")

#No hay evidencias significativas de falta de homocedasticidad en 
#ninguno de los dos test.

#3.Analisis de varianza ANOVA
anova = aov(mademuerta$Densidad ~ mademuerta$Estad_descompos)
summary(anova)

#en al menos uno de los grupos hay diferencia significativa

plot(anova)

#4.Calcular el tamaño del efecto de un ANOVA

eta_cuadrado <- 0.3038/(0.3038 + 1.6728)
eta_cuadrado  # sale 0.15369

#5.Comparaciones m?ltiples

#Necesitamos conocer cual es al menos uno de los grupos que difiere con los 
#demas
pairwise.t.test(x = mademuerta$Densidad, g = mademuerta$Estad_descompos, 
                p.adjust.method = "holm",pool.sd = TRUE, 
                paired = FALSE, alternative = "two.sided")

TukeyHSD(anova)

par(mfrow = c(1,1))
plot(TukeyHSD(anova))

#6.Conclusion
#En el estudio realizado se ha observado un tama?o de efecto peque?o y 
#la tecnicas de inferencia ANOVA han encontrado significancia estadistica
#para aceptar que las medias no son iguales entre todos los grupos.
```

# **_KRUSKAL WALLIS_**

```{r}
#Prueba de Kruskal-Wallis con prueba post-hoc no parametrica
##Ejem: Sokal y Rohlf (1997) presentan un conjunto de datos no publicados
#(W. Purves) en el que el efecto de Tratamientos de az?car en diferentes %
#(Control, 2% de glucosa agregada, 2% de fructosa agregada, 1% de glucosa
#y Se investig? el 1% de fructosa y el 2% de sacarosa en la longitud
#de guisante.


#usamos los datos Purvey
purves <- read.table("purves.csv", header = T, sep = ",")

#vemos las tendencias de normalidad
par(mfrow=c(1, 1))
boxplot(LENGTH ~ TREAT, data = purves) 

ggbetweenstats(
  data = purves,
  x = TREAT,
  y = LENGTH,
  pairwise.display = "no significant"
)

#hay fuertes diferencias de varianzas, tendencia no param?trica

#hacemos el analisis kruskall
kruskal.test(LENGTH~TREAT, data = purves)
#nos dice que si hay diferecnia significativa, la cantidad de azucar
#influencia

#Un estudio compara el numero de huevos que pone la mosca infecciosa Culex
#bajo 3 ambientes distintos. ?Existen diferencias significativas 
#dependiendo de las condiciones?

insecto = data.frame(condicion = c(rep("bosque", 18), rep("potrero", 18), 
                                   rep("ciudad", 18)), n_huevos = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 
                                                                    16, 27, 28, 29, 30, 51, 52, 53, 342, 40, 41, 42, 43, 44, 45, 46,
                                                                    47, 48, 67, 88, 89, 90, 91,92, 93, 94, 293, 19, 20, 21, 22, 23,
                                                                    24, 25, 26, 27, 28, 25, 36, 37, 58, 59, 60, 71, 72))
head(insecto)

aggregate(n_huevos ~ condicion, data = insecto, FUN = median)
aggregate(n_huevos ~ condicion, data = insecto, FUN = sd)

library(ggplot2) #habilitammos el ggplot2

#aplicamos boxplot para ver la dispersion de los datos
ggplot(data = insecto, mapping = aes(x = condicion, y = n_huevos, 
                                     col = condicion)) +   geom_boxplot() +
  theme_bw() + theme(legend.position = "none")

ggbetweenstats(
  data = insecto,
  x = condicion,
  y = n_huevos,
  pairwise.display = "no significant"
)


#aplicamos un histograma
ggplot(data = insecto, mapping = aes(x = n_huevos, colour = condicion)) +
  geom_histogram() + theme_bw() + facet_grid(. ~ condicion) +
  theme(legend.position = "none")


#La representacion grafica de los datos muestra que las muestras no se 
#distribuyen de forma normal, lo que supone una limitacion para emplear 
#un test ANOVA. Las tres muestras presentan el mismo tipo de distribucion,
#asimetria hacia la derecha, a falta de comprobar la homogeneidad de varianza 
#el test de Kruskal-Wallis es la opcion m?s adecuada.


#Condiciones

#Homocedasticidad: la varianza debe de ser constante entre todos los grupos.

library(car)
leveneTest(n_huevos ~ condicion, data = insecto, center = "median")
#No se muestra evidencias en contra de la homogeneidad de varianzas.

#Aplicamos la pruerba de Kruskall wallis

kruskal.test(n_huevos ~ condicion, data = insecto)
#El test encuentra significancia en la diferencia de al menos dos grupos.

#Comparaciones post-hoc para saber que dos grupos difieren
#Existen diferentes m?todos de correcci?n del nivel de significancia, 
#entre ellos destacan el de Bonferroni que es muy estricto y el de holm, 
#este ultimo parece ser m?s recomendado.

pairwise.wilcox.test(x = insecto$n_huevos, g = insecto$condicion, 
                     p.adjust.method = "holm" )
#Solucion
#Entre los tres ambientes hay diferencias significativas en cuanto a la 
#produccion de huevos de las moscas Culex
```

# **_Metodos de ordenación_**

## Analsis de componentes principales PCA

El análisis de componentes principales (PCA) es una técnica multivariada utilizada para explorar y reducir la dimensionalidad de conjuntos de datos grandes y complejos. Su objetivo principal es encontrar patrones o estructuras subyacentes en los datos, lo que permite resumir la información contenida en múltiples variables en un conjunto más pequeño de variables llamadas componentes principales.

Por ejemplo, consideremos un estudio que recolecta datos sobre diferentes ambientes forestales, como la densidad de árboles, la temperatura, la precipitación y la presencia de mamíferos. Estos datos pueden ser representados como puntos en un espacio multidimensional, donde cada dimensión corresponde a una variable medida. El PCA busca identificar combinaciones lineales de estas variables que capturen la mayor cantidad de variabilidad en los datos.

Interpretar los resultados del PCA implica comprender cómo las variables originales contribuyen a cada componente principal identificado. Por ejemplo, si un componente principal captura una gran cantidad de variabilidad en la densidad de árboles y la temperatura, podemos inferir que estas dos variables están fuertemente relacionadas en los datos.

Además, la posición de los puntos en el espacio de componentes principales puede proporcionar información sobre la similitud entre las observaciones. Por ejemplo, si dos puntos están cerca en el espacio de componentes principales, esto sugiere que las observaciones correspondientes son similares en términos de las variables medidas.

En resumen, el PCA es una herramienta poderosa para explorar la estructura de los datos multivariados y puede ayudar a identificar patrones, reducir la dimensionalidad de los datos y entender las relaciones entre las variables.

Analsis multivariados, son datos grandes aleatorios, a traves de estos metodos poder encontrar un orden o agrupacion.
Ejemplo: diferentes ambientes, bosque alto donde hay factores ambientales favorables y otro que seria los animales, otro ambiente donde el bosque es menor y hay mas lluvias por lo cual hay facotres ambientales diferentes y otra variable son los maniferos, y lo que buscamos con la tecnica es relacionar si las varaibles incluyen en la abundancia de mamiferos. Si los datos se agrupan en el centro significa que no estan influenciada


```{r}
# instalamos esos paquetes

library(ggpubr)
library(factoextra)


####################       ANALISIS PCA        ####################

## • Compute PCA using the R base function prcomp()
## • Visualize the output using the factoextra R package (an extension to ggplot2)
## (Kassambara and Mundt, 2017)

nodupca = read.table("nodupca.txt", header = TRUE)

str(nodupca)

library("factoextra")
nodPCA = nodupca # Remove the grouping variable
res.pca = prcomp(nodPCA, scale = TRUE)
fviz_eig(res.pca) ## Para halar el aporte de las varianzas
```
Este gráfico representa las dimensiones y su contribución, donde la primera dimensión aporta un 26% del total. Sin embargo, debido a la gran cantidad de dimensiones, la explicación se vuelve difícil y poco clara. Para abordar esta complejidad, es necesario filtrar las variables más influyentes que puedan explicar las relaciones entre las dimensiones. Esto se debe a que el gran número de variables puede dificultar la comprensión de los patrones subyacentes y hacer que la interpretación sea menos precisa. Al identificar y centrarse en las variables más relevantes, se puede mejorar la comprensión y la interpretación de los datos, permitiendo una visión más clara y significativa de las relaciones presentes en el conjunto de datos.

```{r}
fviz_pca_ind(res.pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE )    # Avoid text overlapping
```

Este análisis indica la presencia de puntos extremos en la distribución de bacterias, lo que sugiere una notable capacidad de adaptación a diferentes niveles de salinidad. Estos puntos extremos podrían indicar cepas de bacterias que pueden sobrevivir y prosperar en condiciones de salinidad muy alta o muy baja. Esta adaptabilidad es un rasgo destacado que puede ser crucial en entornos cambiantes o variables, donde la concentración de salinidad puede fluctuar significativamente. La presencia de estas bacterias extremas puede tener implicaciones importantes en diversos campos, como la biotecnología y la ecología, donde comprender y aprovechar la capacidad de adaptación de organismos puede conducir a aplicaciones innovadoras o a una mejor comprensión de los ecosistemas.

```{r}
fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE  )   # Avoid text overlapping
```

La observación sugiere que la temperatura no ejerce una influencia significativa en el conjunto de datos, ya que su posición en el gráfico está más cerca del centro en comparación con otras variables. Esto podría indicar que la temperatura no es un factor determinante en la variabilidad observada en los datos. Sin embargo, es importante tener en cuenta que esta evaluación se basa únicamente en la posición relativa de la temperatura en el gráfico y no excluye la posibilidad de que la temperatura tenga un impacto en ciertos aspectos específicos o en combinación con otras variables. Por lo tanto, aunque la temperatura no parece ser un factor destacado en este análisis visual, es necesario considerar más información y análisis para comprender completamente su papel en el conjunto de datos.

```{r}
##variables y dimensiones

fviz_pca_biplot(res.pca, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969")  # Individuals color
```


La observación señala que las dimensiones 1 y 2 representan un porcentaje significativo del total, aproximadamente el 21% y el 25% respectivamente. Esto sugiere que estas dos dimensiones capturan una proporción considerable de la variabilidad en los datos. Además, se sugiere que la presencia de tantas variables podría indicar que las bacterias muestran cierta capacidad de resistencia o adaptación a todos los tratamientos aplicados. Esta adaptabilidad generalizada podría reflejar la robustez de las bacterias frente a una variedad de condiciones o factores externos. Sin embargo, es importante tener en cuenta que esta interpretación se basa en la observación de los porcentajes de contribución de las dimensiones y la presencia de múltiples variables en el conjunto de datos, y se requeriría un análisis más detallado para confirmar completamente estas suposiciones y comprender la dinámica subyacente.

```{r}
### Para la variable Temperaturas

nodutemp = read.table("noduTemp.txt", header = TRUE)

nodutemp
library("factoextra")
res.pca = prcomp(nodutemp, scale = TRUE)
fviz_eig(res.pca) ## Para halar el aporte de las varianzas


fviz_pca_biplot(res.pca, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969")  # Individuals color
```
Esta observación resalta que la dimensión uno explica el 44.7% de la variabilidad, seguida por el 30% en la dimensión dos. Además, se destaca que en el centroide no se evidencia un grado de relación o explicación respecto a las variables de temperatura. Se menciona específicamente que el Rhizobium_sp4 logró sobrevivir o soportar la temperatura de 13 grados Celsius. También se señala que las bacterias ubicadas en la parte superior del gráfico no están agrupadas con las otras variables.

Esta descripción sugiere que la dimensión uno tiene un impacto significativo en la variabilidad de los datos, seguida por la dimensión dos. Además, destaca una falta de relación aparente entre el centroide y las variables de temperatura, lo que sugiere que estas últimas podrían no estar directamente asociadas con los patrones observados en el conjunto de datos. La supervivencia o resistencia del Rhizobium_sp4 a una temperatura específica indica una capacidad de adaptación a condiciones ambientales adversas. Por último, la falta de agrupación de las bacterias en la parte superior del gráfico con otras variables puede indicar una diferencia notable en su comportamiento o respuesta a los tratamientos en comparación con las demás bacterias.

```{r}
### Para Salinidad
nodusal = read.table("noduSal.txt", header = TRUE)
res.pca <- prcomp(nodusal, scale = TRUE)
fviz_eig(res.pca) ## Para halar el aporte de las varianzas

fviz_pca_biplot(res.pca, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969")  # Individuals color
```
Esta observación destaca que el 53% de la variabilidad en los datos puede ser explicada por las variables que se encuentran en el lado izquierdo del gráfico. Además, se sugiere que la salinidad 6 está más estrechamente relacionada con esta variabilidad.

Esta interpretación implica que las variables ubicadas en el lado izquierdo del gráfico son las principales contribuyentes a la variabilidad observada en el conjunto de datos. La relación específica con la salinidad 6 indica que este factor podría tener un impacto significativo en los patrones o comportamientos observados en los datos. Esto podría sugerir que la salinidad 6 es un factor importante a considerar al analizar y comprender las dinámicas de las bacterias en el conjunto de datos. Sin embargo, es importante tener en cuenta que esta interpretación se basa en la observación visual y podría requerir un análisis más detallado para confirmar y comprender completamente estas relaciones.

```{r}
### Para pH
noduph = read.table("nodupH.txt", header = TRUE)
res.pca <- prcomp(noduph, scale = TRUE)
fviz_eig(res.pca) ## Para halar el aporte de las varianzas

fviz_pca_biplot(res.pca, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969")  # Individuals color
```


Esta observación destaca una relación significativa entre las bacterias y un pH de 8, donde se puede observar la presencia de la mayoría de las bacterias.

Esta interpretación sugiere que el pH de 8 puede ser un factor clave que influye en la distribución y la abundancia de las bacterias en el conjunto de datos. La concentración de bacterias en este pH específico puede indicar que las condiciones asociadas con un pH de 8 son óptimas o altamente favorables para el crecimiento y la proliferación bacteriana. Esta relación resalta la importancia del pH como un factor ambiental que puede modular la diversidad y la actividad bacteriana en el ecosistema en cuestión.

Sin embargo, es importante recordar que esta interpretación se basa en una observación visual y que se necesitarían análisis adicionales para confirmar y comprender completamente esta relación entre el pH y la distribución de bacterias.



















